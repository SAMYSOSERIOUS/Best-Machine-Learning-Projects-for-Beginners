{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAMYSOSERIOUS/Best-Machine-Learning-Projects-for-Beginners/blob/main/14_Prediction_Miniapp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNZaPRLE8E1g"
      },
      "source": [
        "# Building a prediction \"miniapp\"\n",
        "\n",
        "Assuming we have already successfully trained a model for image classification (or in our case someone else did on [ImageNet](https://image-net.org/) and made it available for download [here](https://www.tensorflow.org/api_docs/python/tf/keras/applications)), we would like to build up a minimalistic web based \"application\" (basically a webpage in static HTML) that can accept an image upload and return the top 3 predictions in a really \"bare bones\" format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SBzH2mY8E1h"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "We will use the minimalist Python webserver [Flask](https://flask.palletsprojects.com/en/2.0.x/) to build our solution.\n",
        "\n",
        "As for easy accessibility through Colab (aka. \"someone else's computer\") we use [Ngrok](https://ngrok.com/) to expose our work to be available from \"outside\" the Colab machine, that is, thorough our browser. Luckily, we don't have to deal to much with this, we just use the [Flask-Ngrok](https://github.com/gstaff/flask-ngrok) package, that handles the hassle for us. Only thing to keep in mind is, that if we run the notebook in Colab, the solution we build will __only be reachable via the ugly looking Ngrok link__, not the \"localhost\" or \"127.0.0.1\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jOv_Cc9EpbVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc77f30-43e0-4589-cf9b-d3ccf3df1ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 318, in __get__\n",
            "    obj = instance._get_current_object()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 519, in _get_current_object\n",
            "    raise RuntimeError(unbound_message) from None\n",
            "RuntimeError: Working outside of application context.\n",
            "\n",
            "This typically means that you attempted to use functionality that needed\n",
            "the current application. To solve this, set up an application context\n",
            "with app.app_context(). See the documentation for more information.\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 318, in __get__\n",
            "    obj = instance._get_current_object()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 519, in _get_current_object\n",
            "    raise RuntimeError(unbound_message) from None\n",
            "RuntimeError: Working outside of application context.\n",
            "\n",
            "This typically means that you attempted to use functionality that needed\n",
            "the current application. To solve this, set up an application context\n",
            "with app.app_context(). See the documentation for more information.\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 318, in __get__\n",
            "    obj = instance._get_current_object()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 519, in _get_current_object\n",
            "    raise RuntimeError(unbound_message) from None\n",
            "RuntimeError: Working outside of request context.\n",
            "\n",
            "This typically means that you attempted to use functionality that needed\n",
            "an active HTTP request. Consult the documentation on testing for\n",
            "information about how to avoid this problem.\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 318, in __get__\n",
            "    obj = instance._get_current_object()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 519, in _get_current_object\n",
            "    raise RuntimeError(unbound_message) from None\n",
            "RuntimeError: Working outside of request context.\n",
            "\n",
            "This typically means that you attempted to use functionality that needed\n",
            "an active HTTP request. Consult the documentation on testing for\n",
            "information about how to avoid this problem.\n"
          ]
        }
      ],
      "source": [
        "!pip install flask --quiet\n",
        "!pip install flask-ngrok --quiet\n",
        "!pip install pyngrok --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwOtg13f8E1i"
      },
      "source": [
        "Fro image formatting we will use the [PIL](https://pillow.readthedocs.io/en/stable/) Python Imaging Library and [Numpy](https://numpy.org/) is always nice to have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2zmjk5K26mT9"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tci-g2GF8E1i"
      },
      "source": [
        "## Downloading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "JJxW3wPVq8m0"
      },
      "outputs": [],
      "source": [
        "from  tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import decode_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8FaziY2OrRDk"
      },
      "outputs": [],
      "source": [
        "model = VGG16()\n",
        "# Luckily, the instantiation of a pretrained model obejct\n",
        "# does a complete download in the background\n",
        "# then initializes the model with the pretrained weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDZijTRw8E1j"
      },
      "source": [
        "## Image preprocessing and prediction functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RU93x_M76JBD"
      },
      "outputs": [],
      "source": [
        "import sys, json\n",
        "\n",
        "def load_image(filename):\n",
        "    \"\"\"Given a filename, assuming it is an image, we load it from disc.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : str\n",
        "        Name of input file.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    PIL Image object\"\"\"\n",
        "    #TODO: use the Image class we imported from PIL to load the image.\n",
        "    #Keep it simple!\n",
        "\n",
        "\n",
        "    image = Image.open(filename)\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "QskFXgSi8E1k"
      },
      "outputs": [],
      "source": [
        "def resize_image(image):\n",
        "    \"\"\"Given a PIL image object we resize it to fit into our downloaded model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : PIL Image object\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    PIL Image object\"\"\"\n",
        "    model_accepted_shape = model.inputs[0].shape[1:3] #ugly magic to get input shape from model\n",
        "    #TODO: please use the shape above to reshape the image with PIL and return the image object\n",
        "    image = image.resize(model_accepted_shape)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "adbu1stl8E1k"
      },
      "outputs": [],
      "source": [
        "def to_numpy(image):\n",
        "    \"\"\"Given a PIL image object we convert it to a Numpy array.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : PIL Image object\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Numpy.Ndarray\"\"\"\n",
        "    array = np.array(image)\n",
        "    #Observe: Numpy is intelligent enough to accept a PIL object as input\n",
        "    #and convert it\n",
        "    return array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Mop8yYx48E1k"
      },
      "outputs": [],
      "source": [
        "def check_channels(array):\n",
        "    \"\"\"Given a numpy tensor we check for it's dimensionality,\n",
        "    and if too many channels are there, we drop 1.\n",
        "    This can be necessary in case of certain PNG images having additional channels.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    array : Ndarray\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Numpy.Ndarray\"\"\"\n",
        "    if array.shape[2]>3:\n",
        "        array = array[:,:,:3]\n",
        "    #Ugly magic to drop a channel - the last one - in cease there are too many\n",
        "    return array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "VNUVC9hi8E1k"
      },
      "outputs": [],
      "source": [
        "def create_batch(array):\n",
        "    \"\"\"Given a numpy tensor we create a single element \"batch\" from it by adding a dimension.\n",
        "    This is necessary because the model was trained with \"minibatches\" of data,\n",
        "    so it assumes, that it does not get one single unput, but a bunch of them at once.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    array : Ndarray\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Numpy.Ndarray\"\"\"\n",
        "    batch = np.expand_dims(array, axis=0)\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rCD2F7V38E1k"
      },
      "outputs": [],
      "source": [
        "def execute_prediction(batch, model):\n",
        "    \"\"\"Given a numpy tensor representing the \"batch\" and the loaded model object,\n",
        "    we execute the prediction.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    batch : Ndarray,\n",
        "    model : TF.Keras.model\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    prediction in Keras model's own format\"\"\"\n",
        "    prediction = model.predict(batch)\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ieeQJEts8E1l"
      },
      "outputs": [],
      "source": [
        "def interpret_prediciton(prediction):\n",
        "    \"\"\"Given Keras model's prediction, we parse it and select the top 3.\n",
        "    For this ve utilize the default `decode_predictions` function of TF.Keras\n",
        "    For more info, see https://www.tensorflow.org/api_docs/python/tf/keras/applications/imagenet_utils/decode_predictions\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    array : Keras model's prediction\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        A dictionary containing the top 3 predictions.\"\"\"\n",
        "    label = decode_predictions(prediction)\n",
        "    decoded_prediction = []\n",
        "    # retrieve the most likely result, e.g. highest probability\n",
        "    for l in label[0][:3]:\n",
        "        print('%s (%.2f%%)' % (l[1], round(l[2]*100,2)))\n",
        "        #some nice formatting to dicts\n",
        "        decoded_prediction.append({\"class\": l[1], \"probability\":round(l[2]*100,2)})\n",
        "    return decoded_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "URYIN2TQ8E1l"
      },
      "outputs": [],
      "source": [
        "def human_format_prediction(decoded_prediction):\n",
        "    \"\"\"Given the processed prediction dict, we modify it to look nice to people\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dict : Interpreted prediction top 3\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        A string representing human readable output.\"\"\"\n",
        "    formatted_output = \"\"\n",
        "    for element in decoded_prediction:\n",
        "        formatted_output += str(element)\n",
        "        formatted_output += \"<br>\" #some nice line breaks in HTML rendering\n",
        "    return formatted_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "pJujECyv8E1l"
      },
      "outputs": [],
      "source": [
        "def json_format_prediction(decoded_prediction):\n",
        "    \"\"\"Given the processed prediction dict, we modify it to become proper JSON\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dict : Interpreted prediction top 3\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        A JSON conformant string representing of the output.\"\"\"\n",
        "    return json.dumps(decoded_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "AdX5O06t8E1l"
      },
      "outputs": [],
      "source": [
        "def do_prediction(filename):\n",
        "    \"\"\"Main prediction function.\n",
        "    - Takes in a filename,\n",
        "    - calls preprocessing steps,\n",
        "    - returns formatted prediction.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : str\n",
        "        Name of input file.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        A string representingoutput.\"\"\"\n",
        "    image = load_image(filename)\n",
        "    image = resize_image(image)\n",
        "    array = to_numpy(image)\n",
        "    array = check_channels(array)\n",
        "    batch = create_batch(array)\n",
        "    prediction = execute_prediction(batch, model)\n",
        "    decoded_prediction = interpret_prediciton(prediction)\n",
        "    formatted_output = human_format_prediction(decoded_prediction)\n",
        "    return formatted_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkzUWktw3EvB"
      },
      "source": [
        "Please observe, that the model will systemmatically err in the direction fo \"slim\" dog breeds, because the way we implemented \"resize\" of the original image - ie. we \"squeeze\" te image to conform to 224x224 pixels!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6pUZ2D38E1l"
      },
      "source": [
        "## Flask app\n",
        "\n",
        "Since we have nice functions that can take in an image and return a prediction, we can now start to develop the mini \"webapp\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBRNcgD78E1l"
      },
      "source": [
        "### Basic HTML page\n",
        "\n",
        "Let's first define a basic HTML page layout tha thas a single control element: an upload \"form\" which can take in files via the browser. This will be our way to feed in the inputs for prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "E8Lf85df4Fxg"
      },
      "outputs": [],
      "source": [
        "HTML = \"\"\"\n",
        "<!doctype html>\n",
        "<html>\n",
        "  <head>\n",
        "    <title>File Upload</title>\n",
        "  </head>\n",
        "  <body>\n",
        "    <h1>File Upload</h1>\n",
        "    <form method=\"POST\" action=\"\" enctype=\"multipart/form-data\">\n",
        "      <p><input type=\"file\" name=\"file\"></p>\n",
        "      <p><input type=\"submit\" value=\"Submit\"></p>\n",
        "    </form>\n",
        "  </body>\n",
        "</html>\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WioWTV3O8E1m"
      },
      "source": [
        "### \"Main app\"\n",
        "\n",
        "Now we define a minimalistic Flask app, that defines single page endpoint at \"/\", so the root URL.\n",
        "\n",
        "If a HTTP (\"GET\") request comes in to this URL, the app will automatically respond by \"serving\" the HTML content we difend above, so the requesting browser can render the \"webpage\" we built.\n",
        "\n",
        "After this the user is free to interact with our wonderful form to choose an appropriate image file. We are assuming here that the user acts non-maliciously, so we do not do all the checks for file content and structure that would protect us, just assume, that the user uploads well behaving image files.\n",
        "\n",
        "When the user pushes \"Submit\", this automatically generates a \"POST\" HTTP request towards our Flask app's \"/\" or \"root\" endpoint and with it, it \"posts\" or sends the image file, which we handle by defining an `upload_file` endpoint, that saves the file and calls on it the `do_prediction` function we defined above. (Please observe, that we don't care about the saved files, so they might accumuate, collide...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "hJq8r9_hprWN"
      },
      "outputs": [],
      "source": [
        "from flask import *\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "#TODO Use the Flask guide to define the simplest possible endpoint for the \"root url\"\n",
        "@app.route('/')\n",
        "def root():\n",
        "    return HTML\n",
        "\n",
        "#TODO Use the Flask guide to define a POST endpoint for the \"root url\"\n",
        "@app.route('/', methods=['POST'])\n",
        "def upload_file():\n",
        "    uploaded_file = request.files['file']\n",
        "    if uploaded_file.filename != '':\n",
        "        uploaded_file.save(uploaded_file.filename)\n",
        "\n",
        "    result = do_prediction(uploaded_file.filename)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLzunDBC8E1m"
      },
      "source": [
        "And finally we start running our \"web application\" via the Ngrok tunnel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEnIz4_UpzED",
        "outputId": "25dda8ad-c536-499d-89c2-5a7c3113b502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel available at: https://a737b8ebcafa.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Address already in use\n",
            "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Terminate ngrok tunnels if any are already running\n",
        "ngrok.kill()\n",
        "\n",
        "# Set the ngrok authtoken directly\n",
        "ngrok.set_auth_token(\"put ngrok token here\")\n",
        "\n",
        "# Start ngrok tunnel on port 5000 (Flask's default port)\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(f\" * ngrok tunnel available at: {public_url}\")\n",
        "\n",
        "# Create a thread to run the Flask app\n",
        "# This prevents app.run() from blocking the notebook\n",
        "def run_flask_app():\n",
        "    app.run(debug=False, use_reloader=False)\n",
        "\n",
        "flask_thread = threading.Thread(target=run_flask_app)\n",
        "flask_thread.daemon = True\n",
        "flask_thread.start()\n",
        "\n",
        "# Wait a bit for the Flask app to start before the notebook cell finishes\n",
        "time.sleep(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiVrjEC08E1m"
      },
      "source": [
        "In case local execution fails, [this](https://githubmemory.com/repo/gstaff/flask-ngrok/issues/20) might help."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2GwX_Ym8E1m"
      },
      "source": [
        "# Testing\n",
        "\n",
        "Please open the temporary ngrok.io link that is visible in the cell output, grab a pictrure from somewhere (eg. an image of a dog) and use the submit functionality!\n",
        "\n",
        "After a single prediction, you can get back to the main form with the back button."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Flask_example.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}